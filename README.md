---
title: AnotaÃ§Ãµes
updated: 2025-02-24 01:01:57Z
created: 2025-02-18 22:20:09Z
latitude: -22.90684670
longitude: -43.17289650
altitude: 0.0000
---

### AnotaÃ§Ãµes gerais, documentaÃ§Ã£o e insights sobre o bootcamp MultiCloud, DevOps e AI Challenge.

&nbsp;

# Dia 01 - Automatizando o provisionamento AWS com Terraform usando Claude

&nbsp;

> **ğŸ’¡InteligÃªncia artificial, multicloud & DevOps juntos estÃ£o moldando o futuro do mercado de TI, criando a base para uma nova era de inovaÃ§Ã£o e automaÃ§Ã£o.**

&nbsp;

**Cronograma do desafio de 5 dias:**

**![816d4b45e541fd7d9492c2dada6308c2.png](_resources/816d4b45e541fd7d9492c2dada6308c2.png)**

&nbsp;

**Projeto que serÃ¡ usado nas prÃ³ximas aulas prÃ¡ticas:**

IntegrarÃ¡ ferramentas DevOps, mÃºltiplas clouds dois assistentes de IA:

**![56d6ffe365ae35c5874b8aa96f749ffa.png](_resources/56d6ffe365ae35c5874b8aa96f749ffa.png)**

&nbsp;

**ğŸ“** **IAM:**Â MÃ©todo de <ins>autenticaÃ§Ã£o</ins> para facilitar a autenticaÃ§Ã£o das mÃ¡quinas virtuais, atravÃ©s de roles  
**ğŸ“ EC2:** Amazon Elastic Compute Cloud (EC2) Ã© um serviÃ§o da Amazon que permite criar e executar aplicaÃ§Ãµes na nuvem. Ele oferece capacidade computacional escalÃ¡vel e redimensionÃ¡vel  
**ğŸ“ S3:** O S3 Ã© uma soluÃ§Ã£o de armazenamento de objetos que permite armazenar e recuperar dados de qualquer lugar do mundo.

&nbsp;

**AULA PRÃTICA**

CÃ³digo Terraform para criar um bucket S3 na AWS com um nome Ãºnico na regiÃ£o us-east-1:

```Terraform
provider "aws" {
  region = "us-east-1"  # Substitua pela regiÃ£o desejada
}

resource "random_id" "bucket_suffix" {
  byte_length = 8
}

resource "aws_s3_bucket" "my_bucket" {
  bucket = "my-unique-bucket-name-${random_id.bucket_suffix.hex}"

  tags = {
    Name        = "My bucket"
    Environment = "Dev"
  }
}
```

&nbsp;

Inicializar o Terraform  
`terraform init`

Planejar o que serÃ¡ criado  
`terraform plan`

Provisionar os recursos  
`terraform apply`  
<br/>Listar os buckets criados via CLI  
`aws s3 ls`

Excluir os recursos criados  
`terraform destroy`

![af4650585192c39e464f23139800b6f9.png](_resources/af4650585192c39e464f23139800b6f9.png)

&nbsp;

# Dia 02 - Implantando a aplicaÃ§Ã£o com Docker & Kubernetes na AWS

&nbsp;

> **ğŸ’¡VisÃ£o estratÃ©gica:** Mesmo que eu jÃ¡ esteja em uma posiÃ§Ã£o confortÃ¡vel no mercado de trabalho, Ã© importante sempre estar atualizado das novas tecnologias e tendÃªncias atuais.

&nbsp;

**ğŸ“ Docker** Ã© uma tecnologia que permite empresas empacotar, entregar e executar aplicaÃ§Ãµes e suas dependÃªncias (bibliotecas) de forma padronizada.

**Estrutura de uma aplicaÃ§Ã£o containerizada**

- MÃ¡quina virtual
- Sistema operacional
- Containers com as aplicaÃ§Ãµes, bibliotecas e dependÃªncias

![b5a118b035fc83ccd49c781ec3041ec8.png](_resources/b5a118b035fc83ccd49c781ec3041ec8.png)

&nbsp;

**Docker: casos de uso**

**ModernizaÃ§Ã£o das aplicaÃ§Ãµes "tradicionais" para MicrosserviÃ§os**  
Â - Se um container falhar, apenas uma parte da aplicaÃ§Ã£o ficarÃ¡ indisponÃ­vel.  
Â - Novas implementaÃ§Ãµes sem afetar outros componentes/serviÃ§os.

**PadronizaÃ§Ã£o dos deployments**  
Â - As imagens docker construÃ­das atravÃ©s de arquivos de definiÃ§Ã£o.

**Ambientes semelhantes**  
Â - Docker roda em qualquer lugar  
Â - Basta ter o docker instalado

&nbsp;

**ğŸ“ Kubernetes:** Sistema de <ins>orquestraÃ§Ã£o</ins> de containers mais popular, criado pela Google para gerir seus aplicativos internos:

- Estrutura organizada em forma de objetos ou componentes do K8S.
- ImplementaÃ§Ã£o baseada em um simples arquivo de texto (.yaml).
- SoluÃ§Ã£o open source e suportada por mÃºltiplos servidores de cloud (multicloud).

&nbsp;

**ğŸ¯ Como o Docker vai me ajudar na minha carreira?**

- Aprender Docker Ã© o primeiro passo para avanÃ§ar para o prÃ³ximo nÃ­vel: Kubernetes
- AplicaÃ§Ãµes modernas fazem uso de arquitetura de microsserviÃ§os
- Existem outros container runtime, mas Docker Ã© o mais popular.
- Terraform Ã© a evoluÃ§Ã£o da infra; Docker Ã© a evoluÃ§Ã£o das aplicaÃ§Ãµes.

&nbsp;

**ğŸ¯ Como o Kubernetes vai me ajudar na minha carreira?**

- Kubernetes estÃ¡ presente desde pequenas startups a grandes empresas.
- Kubernetes Ã© o presente e futuro de aplicaÃ§Ãµes modernas rodando em multicloud
- Sobre orquestradores de containers, Kubernetes Ã© sem dÃºvidas o mais popular
- Kubernetes Ã© fundamental para empresas que executam aplicaÃ§Ãµes na nuvem.

&nbsp;

Como uma **VM** funciona?

Cada VM Possui: App, SO, Kernel, Libs e Deps

- Alta utilizaÃ§Ã£o de recursos (OS/Kernel);
- Alto consumo de disco (GB);
- InicializaÃ§Ã£o: minutos

![3f8f15f6f116d3f36b670693048e0990.png](_resources/3f8f15f6f116d3f36b670693048e0990.png)

&nbsp;

Como o **Docker** funciona?

Cada **container** possui: App, Libs e Deps;

- Baixa utilizaÃ§Ã£o de recursos (apenas uma pequena parte do Kernel);
- Baixo consumo de disco (MB);
- InicializaÃ§Ã£o: segundos.

![0b9085ac38d591c6e2d46043d0e2233e.png](_resources/0b9085ac38d591c6e2d46043d0e2233e.png)

&nbsp;

**Como o Kubernetes funciona?**

O Kubernetes gerencia automaticamente os contÃªineres dentro de um cluster de servidores.  
<br/>O nÃ³ <ins>Master</ins> gerencia o cluster, enquanto os nÃ³s <ins>Workers</ins> executam as aplicaÃ§Ãµes. Se um nÃ³ falhar, a aplicaÃ§Ã£o continua funcionando porque o Kubernetes redistribui automaticamente os contÃªineres para outros nÃ³s disponÃ­veis. O Kubernetes precisa estar instalado em todos os nÃ³s para que funcione corretamente.

&nbsp;

ğŸ“ **DynamoDB** Ã© o serviÃ§o de banco de dados da AWS. Vamos criar as tabelas do banco usando **Terraform**. Hoje, vamos aprender como rodar a aplicaÃ§Ã£o localmente, <ins>antes</ins> de aprofundarmos com o Kubernetes.

&nbsp;

**AULA PRÃTICA**

**Criar as tabelas do CloudMart usando Terraform**

```Terraform
provider "aws" {
  region = "us-east-1"  # Altere para sua regiÃ£o preferida
}

# Tabelas DynamoDB
resource "aws_dynamodb_table" "cloudmart_products" {
  name           = "cloudmart-products"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}

resource "aws_dynamodb_table" "cloudmart_orders" {
  name           = "cloudmart-orders"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}

resource "aws_dynamodb_table" "cloudmart_tickets" {
  name           = "cloudmart-tickets"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}
```

O cÃ³digo acima criarÃ¡ **3 tabelas.** Uma armazenarÃ¡ os dados de <ins>produtos</ins>, outra de <ins>pedidos</ins> e uma de <ins>tickets</ins>.  
`billing_mode = "PAY_PER_REQUEST"` indicaÂ  que as configuraÃ§Ãµes de pagamento geradas pela aplicaÃ§Ã£o na AWS serÃ£o <ins>por request</ins>.

`terraform init` > Inicializar o terraform  
`terraform plan` > Plano do que vamos criar  
`terraform apply` > Provisionar os recursos do arquivo `main.tf`

**ConteÃºdo do arquivo** `.env`

```.env
PORT=5000
AWS_REGION=us-east-1
BEDROCK_AGENT_ID=<seu-bedrock-agent-id>
BEDROCK_AGENT_ALIAS_ID=<seu-bedrock-agent-alias-id>
OPENAI_API_KEY=<sua-chave-api-openai>
OPENAI_ASSISTANT_ID=<seu-id-assistente-openai>
```

&nbsp;

**ConteÃºdo do** `Dockerfile`

```Dockerfile
FROM node:18
WORKDIR /usr/src/app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 5000
CMD ["npm", "start"]
```

ğŸ“ **Dockerfile:** representaÃ§Ã£o da "planta baixa" do backend.

ğŸ“ **FROM**: imagem base, como se fosse a ISO de um sistema operacional.

&nbsp;

**Construir e executar a imagem Docker:  
**`docker build -t cloudmart-backend .` -> Este comando cria uma imagem Docker a partir de um **Dockerfile** no diretÃ³rio atual (**.**). A opÃ§Ã£o `-t` define o nome da imagem como *cloudmart-backend*.

`docker run -d -p 5000:5000 --env-file .env cloudmart-backend`

Este comando executa a imagem **cloudmart-backend** em um container Docker. A opÃ§Ã£o **\-d** faz com que o container seja executado em segundo plano (detached mode). **\-p 5000:5000 mapeia** a porta 5000 do container para a porta 5000 da mÃ¡quina local. **\--env-file .env** carrega variÃ¡veis de ambiente a partir do arquivo **.env** para dentro do container.

&nbsp;

`docker ps` lista os containers rodando atualmente

`docker logs ID_DO_CONTAINER` trarÃ¡ o log detalhado do que estÃ¡ rodando no container.

**ConteÃºdo do .env do frontend**:  
`VITE_API_BASE_URL=http://<seu-ip-ec2>:5000/api`

&nbsp;

**ConteÃºdo do Dockerfile do frontend**:

```Dockerfile
FROM node:16-alpine as build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:16-alpine
WORKDIR /app
RUN npm install -g serve
COPY --from=build /app/dist /app
ENV PORT=5001
ENV NODE_ENV=production
EXPOSE 5001
CMD ["serve", "-s", ".", "-l", "5001"]
```

&nbsp;

**Construir e executar a imagem Docker**

`docker build -t cloudmart-frontend .`  
`docker run -d -p 5001:5001 cloudmart-frontend`

&nbsp;

&nbsp;

# Dia 03 - Colocando a aplicaÃ§Ã£o Cloud no piloto automÃ¡tico com pipelines DevOps CI/CD na AWS

&nbsp;

> ğŸ’¡**A importÃ¢ncia do portfÃ³lio**: treinar cenÃ¡rios de casos reais e documentÃ¡-los em um portfÃ³lio pode gerar uma visÃ£o positiva por parte dos recrutadores.
> 
> ğŸ’¡ Documentar portfÃ³lio no **medium.com** e postar no **LinkedIn.**

&nbsp;

**ğŸ“ ECR Elastic Container Registry:** Permite armazenar, gerenciar e implantar imagens de contÃªineres.

**ğŸ“ EKS (Elastic Kubernetes Services):** Permite executar aplicaÃ§Ãµes do Kubernetes na AWS ou em ambientes locais.

  
âš ï¸ **Importante:** lembrar de <ins>deletar</ins> o cluster quando terminar a aula prÃ¡tica, para evitar <ins>cobranÃ§as indesejadas</ins>.

**AULA PRÃTICA**

Ontem subimos a aplicaÃ§Ã£o na EC2, hoje vamos subir a mesma aplicaÃ§Ã£o dentro do Kubernetes (EKS).

**Suporte padrÃ£o da versÃ£o do Kubernetes: Â  Â  Â  Â  USD 0,10 por cluster/hora**  
**Suporte estendido da versÃ£o do Kubernetes:Â  Â  Â USD 0,60 por cluster/hora**

1 - Crie um usuÃ¡rio chamado *ekuser* atravÃ©sÂ  do IAM. "Especificar detalhes do usuÃ¡rio" >> "anexar polÃ­ticas diretamente".  
2 - Dar as permissÃµes atravÃ©s do Credenciais de seguranÃ§a >> Criar chave de acesso >> Command Line Interface (CLI).  
3 - Para configurar a instÃ¢ncia EC2 com o usuÃ¡rio *eksuser* que acabamos de criar, vamos digitar `aws configure`.

4 - Instalar a ferramenta **eksctl**.  
`curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp`  
`sudo cp /tmp/eksctl /usr/bin`  
`eksctl version`

**ğŸ“ eksctl** Ã© uma ferramenta de linha de comando que facilita a criaÃ§Ã£o e gerenciamento de clusters Kubernetes no Amazon EKS (Elastic Kubernetes Service). Com o eksctl, vocÃª pode <ins>criar, atualizar e excluir clusters</ins> no EKS de forma simples, sem precisar fazer configuraÃ§Ãµes complexas. Ã‰ como um "ajudante" para interagir com o EKS de forma mais fÃ¡cil e rÃ¡pida.

5 - Instalar a ferramenta **kubectl**

`curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.18.9/2020-11-02/bin/linux/amd64/kubectl`  
`chmod +x ./kubectl`  
`mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin`  
`echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc`  
`kubectl version --short --client`

**ğŸ“ kubectl** Ã© a ferramenta CLI oficial do Kubernetes. Com o kubectl, vocÃª pode interagir com qualquer cluster Kubernetes. Ele Ã© usado para executar comandos como criar pods, gerenciar serviÃ§os, verificar o estado do cluster, entre outras coisas.

&nbsp;

6 - Crie um EKS Cluster (processo mais demorado).

NÃ³s criaremos somente 1 nÃ³ (`nodes 1`), mas num cenÃ¡rio real Ã© normal ter mais instÃ¢ncias espalhadas em zonas de disponibilidade diferentes (pelo menos uns 3 nÃ³s).

ğŸ“ No backgroud, a AWS usa o **Cloud Formation** (ferramenta semelhante ao Kubernetes) para subir essa infra.

TambÃ©m Ã© possÃ­vel subir o cluster usando o terraform.

```Shell
eksctl create cluster \  
Â Â --name cloudmart \  
Â Â --region us-east-1 \  
Â Â --nodegroup-name standard-workers \  
Â Â --node-type t3.medium \  
Â Â --nodes 1 \  
Â Â --with-oidc \  
Â Â --managed
```

Ou (em uma linha) `eksctl create cluster --name cloudmart --region us-east-1 --nodegroup-name standard-workers --node-type t3.medium --nodes 1 --with-oidc --managed`

7 - Conecte-se ao cluster EKS usando a configuraÃ§Ã£o do **kubectl**  
`aws eks update-kubeconfig --name cloudmart`

8 - Verifique a conectividade do Cluster  
`kubectl get svc` para listar todos os serviÃ§os do cluster.  
`kubectl get nodes` para listar todos os nÃ³s do cluster.

9 - Crie uma **Role & Service Account** para fornecer aos pods acesso aos serviÃ§os usados pela aplicaÃ§Ã£o (DynamoDB, Bedrock, etc).

O propÃ³sito dessa conta Ã© que a aplicaÃ§Ã£o consiga acessar recursos como DynamoDB, bedrock etc, dando permissÃ£o atravÃ©s de uma service account.

```Shell
eksctl create iamserviceaccount \  
Â Â --cluster=cloudmart \  
Â Â --name=cloudmart-pod-execution-role \  
Â Â --role-name CloudMartPodExecutionRole \  
Â Â --attach-policy-arn=arn:aws:iam::aws:policy/AdministratorAccess\  
Â Â --region us-east-1 \  
Â Â --approve
```

Ou (em uma linha)Â `eksctl create iamserviceaccount --cluster=cloudmart --name=cloudmart-pod-execution-role --role-name CloudMartPodExecutionRole --attach-policy-arn=arn:aws:iam::aws:policy/AdministratorAccess --region us-east-1 --approve`

Verificar se temos algum deploy:  
`kubectl get deployment`

OBS: No exemplo acima, foram usados privilÃ©gios de Admin para facilitar fins educacionais. Lembre-se sempre de seguir o princÃ­pio do **mÃ­nimo privilÃ©gio** em ambientes de produÃ§Ã£o.

&nbsp;

**ğŸ“ Deployment**: Ã© a representaÃ§Ã£o de como vocÃª quer ver um componente especÃ­fico da sua aplicaÃ§Ã£o dentro do Kubernetes.  
**ğŸ“ POD:** Ã© a mÃ­nima unidade que representa um ou mais containers.

ğŸ’­ Imagine que vocÃª tem um restaurante:  
O **Deployment** seria como o <ins>gerente</ins> do restaurante, garantindo que sempre haja cozinheiros suficientes para atender a demanda.  
Os **Pods** sÃ£o os <ins>cozinheiros</ins>, que realmente fazem o trabalho (rodando a aplicaÃ§Ã£o).  
O **ReplicaSet** garante que sempre haja o <ins>nÃºmero correto de cozinheiros</ins> disponÃ­veis (se um cozinheiro sair, ele contrata outro automaticamente).  
O **Service** funciona como o <ins>garÃ§om</ins>, que recebe os pedidos dos clientes e os direciona para um cozinheiro disponÃ­vel.

![1d5face54e525b818413770a87b2aa01.png](_resources/1d5face54e525b818413770a87b2aa01.png)

Na imagem:

- Vemos um Deployment que gerencia vÃ¡rios Pods da aplicaÃ§Ã£o "A".
- Esses Pods estÃ£o sob um ReplicaSet, que garante que eles continuem rodando corretamente.
- O Service (svc) age como um ponto de entrada, encaminhando as solicitaÃ§Ãµes para qualquer Pod da aplicaÃ§Ã£o "A".
- A label app=A Ã© usada para identificar quais Pods pertencem a essa aplicaÃ§Ã£o.

&nbsp;

**Deployment do Backend no Kubernetes**

Crie um RepositÃ³rio ECR para o Backend e suba a imagem Docker para o mesmo (Seguir os passos de criaÃ§Ã£o, no gerenciador do ECR no site da AWS).

**Crie um arquivo de deployment do Kubernetes (YAML) para o Backend**

`cd challenge-day2/backend`  
`vim cloudmart-backend.yaml`

&nbsp;

```YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudmart-backend-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudmart-backend-app
  template:
    metadata:
      labels:
        app: cloudmart-backend-app
    spec:
      serviceAccountName: cloudmart-pod-execution-role
      containers:
      - name: cloudmart-backend-app
        image: public.ecr.aws/l4c0j8h9/cloudmart-backend:latest
        env:
        - name: PORT
          value: "5000"
        - name: AWS_REGION
          value: "us-east-1"
        - name: BEDROCK_AGENT_ID
          value: "xxxxxx"
        - name: BEDROCK_AGENT_ALIAS_ID
          value: "xxxx"
        - name: OPENAI_API_KEY
          value: "xxxxxx"
        - name: OPENAI_ASSISTANT_ID
          value: "xxxx"
---

apiVersion: v1
kind: Service
metadata:
  name: cloudmart-backend-app-service
spec:
  type: LoadBalancer
  selector:
    app: cloudmart-backend-app
  ports:
    - protocol: TCP
      port: 5000
      targetPort: 5000
```

&nbsp;

**Realize o deployment do Backend no Kubernetes**  
`kubectl apply -f cloudmart-backend.yaml`

Acompanhe o status dos objetos sendo criados e obtenha o IP pÃºblico gerado para a API  
`kubectl get pods`  
`kubectl get deployment`  
`kubectl get service`

&nbsp;

**Deployment do Frontend no Kubernetes**

**1 - PreparaÃ§Ã£o**  
Altere o arquivo .env do Frontend para apontar para a URL da API criada dentro do Kubernetes obtida pela comando kubectl get service  
`cd ../challenge-day2/frontend`  
`nano .env`

**2 - ConteÃºdo do .env:**  
`VITE_API_BASE_URL=http://<sua_url_kubernetes_api>:5000/api`

**3 - Crie um RepositÃ³rio ECR para o Frontend e suba a imagem Docker para o mesmo**  
&lt;Siga os passos do ECR&gt;

**4 - Crie um arquivo de deployment do Kubernetes (YAML) para o Frontend**  
`cd challenge-day2/frontend`  
`nano cloudmart-frontend.yaml`

```YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudmart-frontend-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudmart-frontend-app
  template:
    metadata:
      labels:
        app: cloudmart-frontend-app
    spec:
      serviceAccountName: cloudmart-pod-execution-role
      containers:
      - name: cloudmart-frontend-app
        image: public.ecr.aws/l4c0j8h9/cloudmart-frontend:latest
---

apiVersion: v1
kind: Service
metadata:
  name: cloudmart-frontend-app-service
spec:
  type: LoadBalancer
  selector:
    app: cloudmart-frontend-app
  ports:
    - protocol: TCP
      port: 5001
      targetPort: 5001
```

&nbsp;

**Realize o deployment do Frontend no Kubernetes**  
`kubectl apply -f cloudmart-frontend.yaml`  
â€‹  
**Acompanhe o status dos objetos sendo criados e obtenha o IP pÃºblico gerado para a API**  
`kubectl get pods`  
`kubectl get deployment`  
`kubectl get service`

&nbsp;

**ğŸ“ Resumo do que fizemos atÃ© agora:**

- Criamos o arquivo de Docker (dockerfile) com as configuraÃ§Ãµes
- Fizemos o build da imagem com o Docker
- Fizemos a criaÃ§Ã£o do ECR e push para enviar a imagem da aplicaÃ§Ã£o para o repositÃ³rio remoto na AWS
- No Kubernetes criamos o arquivo de deployment e rodamos o `kubectl apply` para provisionar o backend e frontend.

Esses sÃ£o os passos que terÃ­amos que fazer **manualmente** para provisionar a aplicaÃ§Ã£o, caso alguÃ©m solicitasse uma mudanÃ§a no app.

==Agora, vamos implementar o **pipeline CI/CD** para que a aplicaÃ§Ã£o seja atualizada no **piloto automÃ¡tico** sempre que houver uma mudanÃ§a no cÃ³digo.==

Para o nosso exercÃ­cio, vamos criar uma pipeline para o frontend com duas etapas:

&nbsp;- Na primeira etapa, vamos fazer o processo de build da imagem do docker que pegarÃ¡ no github as atualizaÃ§Ãµes e criarÃ¡ uma imagem nova  
Â - Na segunda etapa, a imagem serÃ¡ provisionada automaticamente dentro do cluster de kubernetes atravÃ©s do **codebuild**.

O **ECR** sÃ³ estÃ¡ armazenando as imagens do **Docker** e o **Kubernetes** estÃ¡ provisionando containers, que entregarÃ£o o backend e frontend da aplicaÃ§Ã£o.

&nbsp;

Para conectarmos o nosso Github com a EC2, vamos precisar fazer o passo a passo para clonar o repositÃ³rio para a mÃ¡quina virtual.

`echo "# bootcamp-tcb-multicloud-devops-ai-challenge" >> README.md`  
`git init`  
`git add README.md`  
`git commit -m "first commit"`  
`git branch -M main`  
`git remote add origin git@github.com:0isouza/bootcamp-tcb-multicloud-devops-ai-challenge.git`  
`git push -u origin main`

**âš ï¸ RemoÃ§Ã£o**  
**Ao final do hands-on, delete todos os recursos para evitar cobranÃ§as indesejadas:**  
`kubectl delete service cloudmart-frontend-app-service`  
`kubectl delete deployment cloudmart-frontend-app`  
`kubectl delete service cloudmart-backend-app-service`  
`kubectl delete deployment cloudmart-backend-app`

`eksctl delete cluster --name cloudmart --region us-east-1`

&nbsp;

# Dia 04 Criando agentes de IA com OpenAI e Amazon Bedrock

&nbsp;

> ğŸ’¡ Reserve tempo para **estudar**. Se vocÃª deixar sua carreira em segundo plano, o mercado de trabalho tambÃ©m te deixarÃ¡ em **segundo plano**.

&nbsp;

Jensen Huang, CEO da NVIDIA, fez uma previsÃ£o audaciosa na CES 2025. Essa visÃ£o futurista reflete uma transformaÃ§Ã£o jÃ¡ em curso, impulsionada pelos avanÃ§os em inteligÃªncia artificial.

**O departamento de TI de cada empresa serÃ¡ o departamento de RH de agentes de IA no futuro. Eles nÃ£o apenas mantÃªm sistemas, mas cuidam de agentes digitais que realizam tarefas crÃ­ticas para os negÃ³cios.**

*The IT department of every company is going to be the HR department of AI agents in the future. Today (IT Departments) manage and maintain a bunch of software from the IT industry. In the future they will maintain, nurture and onboard and improve a whole bunch of digital agents and provision them to the companies to use. Your IT department is going to become kind of like AI-agent HR.*

&nbsp;

**InteligÃªncia Artificial e sua importÃ¢ncia**

Hierarquia da InteligÃªncia Artificial:

Artificial Inteligence (AI)  
Â  Â  Â  Â - Narrow AI  
Â  Â  Â  Â  Â  Â  Â  Â  - Machne Learning (ML)  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  - Deep Learning  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  - Generative AI (GenAI)  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  - Large Language Models (LLM)  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  - Tools: *ChatGPT, Copilot, Gemini, etc*.

Foundations Models sÃ£o frequentemente referidos como sinÃ´nimos de LLMs, devido Ã s suas capacidades amplas adaptÃ¡veis.

&nbsp;

**AULA PRÃTICA**

Vamos criar 2 assistentes de IA. Um serÃ¡ um **assistente de compras pessoais** e outro serÃ¡ um **assistente de suporte**.

**CriaÃ§Ã£o de recursos usando o Terraform**  
Navegue para a pasta que contÃ©m o arquivo main.tf e baixe o arquivo zip contendo a funÃ§Ã£o Lambda que serÃ¡ usada pelo Bedrock  
`cd challenge-day2/backend/src/lambda`  
`cp list_products.zip terraform-project/`  
`cd terraform-project`  
<br/>

Adicione as linhas abaixo no final do arquivo `main.tf`

```Terraform
# IAM Role for Lambda function
resource "aws_iam_role" "lambda_role" {
  name = "cloudmart_lambda_role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "lambda.amazonaws.com"
        }
      }
    ]
  })
}

# IAM Policy for Lambda function
resource "aws_iam_role_policy" "lambda_policy" {
  name = "cloudmart_lambda_policy"
  role = aws_iam_role.lambda_role.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "dynamodb:Scan",
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents"
        ]
        Resource = [
          aws_dynamodb_table.cloudmart_products.arn,
          aws_dynamodb_table.cloudmart_orders.arn,
          aws_dynamodb_table.cloudmart_tickets.arn,
          "arn:aws:logs:*:*:*"
        ]
      }
    ]
  })
}

# Lambda function for listing products
resource "aws_lambda_function" "list_products" {
  filename         = "list_products.zip"
  function_name    = "cloudmart-list-products"
  role             = aws_iam_role.lambda_role.arn
  handler          = "index.handler"
  runtime          = "nodejs20.x"
  source_code_hash = filebase64sha256("list_products.zip")

  environment {
    variables = {
      PRODUCTS_TABLE = aws_dynamodb_table.cloudmart_products.name
    }
  }
}

# Lambda permission for Bedrock
resource "aws_lambda_permission" "allow_bedrock" {
  statement_id  = "AllowBedrockInvoke"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.list_products.function_name
  principal     = "bedrock.amazonaws.com"
}

# Output the ARN of the Lambda function
output "list_products_function_arn" {
  value = aws_lambda_function.list_products.arn
}
```

&nbsp;

**ConfiguraÃ§Ã£o do Agente Amazon Bedrock**  
<br/>Â - Solicitar acesso ao Cloud 3.0 Sonnet no Amazon Bedrock  
<br/>**Criar o Agente:**  
1 - No console Amazon Bedrock, escolha "Agents" em "Builder tools" no painel de navegaÃ§Ã£o.  
2 - Clique em "Create agent".  
3 - Nomeie o agente "cloudmart-product-recommendation-agent".  
4 - Selecione "Claude 3 Sonnet" como o modelo base.  
5 - Cole as instruÃ§Ãµes do agente abaixo na seÃ§Ã£o "Instructions for the Agent".

```Plain
You are a product recommendations agent for CloudMart, an online e-commerce store. Your role is to assist customers in finding products that best suit their needs. Follow these instructions carefully:

1. Begin each interaction by retrieving the full list of products from the API. This will inform you of the available products and their details.

2. Your goal is to help users find suitable products based on their requirements. Ask questions to understand their needs and preferences if they're not clear from the user's initial input.

3. Use the 'name' parameter to filter products when appropriate. Do not use or mention any other filter parameters that are not part of the API.

4. Always base your product suggestions solely on the information returned by the API. Never recommend or mention products that are not in the API response.

5. When suggesting products, provide the name, description, and price as returned by the API. Do not invent or modify any product details.

6. If the user's request doesn't match any available products, politely inform them that we don't currently have such products and offer alternatives from the available list.

7. Be conversational and friendly, but focus on helping the user find suitable products efficiently.

8. Do not mention the API, database, or any technical aspects of how you retrieve the information. Present yourself as a knowledgeable sales assistant.

9. If you're unsure about a product's availability or details, always check with the API rather than making assumptions.

10. If the user asks about product features or comparisons, use only the information provided in the product descriptions from the API.

11. Be prepared to assist with a wide range of product inquiries, as our e-commerce store may carry various types of items.

12. If a user is looking for a specific type of product, use the 'name' parameter to search for relevant items, but be aware that this may not capture all categories or types of products.

Remember, your primary goal is to help users find the best products for their needs from what's available in our store. Be helpful, informative, and always base your recommendations on the actual product data provided by the API.
```

&nbsp;  
**Configurar a FunÃ§Ã£o IAM:**  
1 - Na visÃ£o geral do Agente Bedrock, localize a seÃ§Ã£o 'Permissions'.  
2 - Clique no link da funÃ§Ã£o IAM. Isso o levarÃ¡ ao console IAM com a funÃ§Ã£o correta selecionada.  
3 - No console IAM, escolha "Add permissions" e depois "Create inline policy".  
4 - Na aba JSON, cole a seguinte polÃ­tica:

```JSON
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "lambda:InvokeFunction",
      "Resource": "arn:aws:lambda:*:*:function:cloudmart-list-products"
    },
    {
      "Effect": "Allow",
      "Action": "bedrock:InvokeModel",
      "Resource": "arn:aws:bedrock:*::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0"
    }
  ]
}
```

1 - Substitua cloudmart-list-products pelo nome real da sua funÃ§Ã£o Lambda, se for diferente.  
2 - Nomeie a polÃ­tica (por exemplo, "BedrockAgentLambdaAccess") e crie-a.  
3 - Verifique se a nova polÃ­tica estÃ¡ anexada Ã  funÃ§Ã£o.

&nbsp;

**Configurar o Action Group:**  
1 - Na seÃ§Ã£o "Action groups", crie um novo grupo chamado "Get-Product-Recommendations".  
2 - Defina o tipo de grupo de aÃ§Ã£o como "Define with API schemas".  
3 - Selecione a funÃ§Ã£o Lambda "cloudmart-list-products" como executor do grupo de aÃ§Ã£o.  
4 - Na seÃ§Ã£o "Action group schema", escolha "Define via in-line schema editor".  
5 - Cole o esquema OpenAPI abaixo no editor de esquema:

```OpenAPI
{
    "openapi": "3.0.0",
    "info": {
        "title": "Product Details API",
        "version": "1.0.0",
        "description": "This API retrieves product information. Filtering parameters are passed as query strings. If query strings are empty, it performs a full scan and retrieves the full product list."
    },
    "paths": {
        "/products": {
            "get": {
                "summary": "Retrieve product details",
                "description": "Retrieves a list of products based on the provided query string parameters. If no parameters are provided, it returns the full list of products.",
                "parameters": [
                    {
                        "name": "name",
                        "in": "query",
                        "description": "Retrieve details for a specific product by name",
                        "schema": {
                            "type": "string"
                        }
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Successful response",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "array",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "name": {
                                                "type": "string"
                                            },
                                            "description": {
                                                "type": "string"
                                            },
                                            "price": {
                                                "type": "number"
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    },
                    "500": {
                        "description": "Internal Server Error",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "$ref": "#/components/schemas/ErrorResponse"
                                }
                            }
                        }
                    }
                }
            }
        }
    },
    "components": {
        "schemas": {
            "ErrorResponse": {
                "type": "object",
                "properties": {
                    "error": {
                        "type": "string",
                        "description": "Error message"
                    }
                },
                "required": [
                    "error"
                ]
            }
        }
    }
}
```

&nbsp;

**ConfiguraÃ§Ã£o do Assistente OpenAI**

**Acesso ao OpenAI**

Acesse a plataforma OpenAI (https://platform.openai.com/).  
FaÃ§a login ou crie uma conta se ainda nÃ£o tiver uma.

**Criar o Assistente**  
1 - Navegue atÃ© a seÃ§Ã£o "Assistants".  
2 - Clique em "Create New Assistant".  
3 - Nomeie o assistente "CloudMart Customer Support".  
4 - Selecione o modelo gpt-4o.

**Configurar o Assistente:**  
Na seÃ§Ã£o "Instructions", cole o seguinte:

*VocÃª Ã© um agente de suporte ao cliente para CloudMart, uma plataforma de e-commerce. Seu papel Ã© auxiliar os clientes com consultas gerais, problemas de pedidos e fornecer informaÃ§Ãµes Ãºteis sobre o uso da plataforma CloudMart. VocÃª nÃ£o tem acesso direto a informaÃ§Ãµes especÃ­ficas de produtos ou inventÃ¡rio. Seja sempre educado, paciente e foque em fornecer um excelente atendimento ao cliente. Se um cliente perguntar sobre produtos especÃ­ficos ou inventÃ¡rio, explique educadamente que vocÃª nÃ£o tem acesso a essas informaÃ§Ãµes e sugira que eles verifiquem o site ou falem com um representante de vendas.*  
â€‹  
Em "Capabilities", vocÃª pode habilitar "Code Interpreter" se quiser que o assistente ajude com aspectos tÃ©cnicos do uso da plataforma.

**Salvar o Assistente:**  
1 - Clique em "Save" para criar o assistente.  
2 - Anote o ID do Assistente, vocÃª precisarÃ¡ dele para suas variÃ¡veis de ambiente.

**Gerar Chave de API:**  
1 - VÃ¡ para a seÃ§Ã£o API Keys em sua conta OpenAI.  
2 - Gere uma nova chave de API.  
3 - Copie esta chave, vocÃª precisarÃ¡ dela para suas variÃ¡veis de ambiente.

==As assistentes de IA atuais podem chamar **funÃ§Ãµes via API** que tomam aÃ§Ãµes que **atendentes humanos** tomariam, como cancelar pedidos, alterar dados de contas, realizar pagamentos ou fornecer suporte tÃ©cnico, otimizando processos e melhorando a eficiÃªncia no atendimento ao cliente.==

&nbsp;

**FaÃ§a o redeployment do backend com os AI Assistants**

Atualize o arquivo cloudmart-backend.yaml com as informaÃ§Ãµes dos AI Assistants:  
Abra o arquivo cloudmart-backend.yaml.  
`nano cloudmart-backend.yaml`

ConteÃºdo do cloudmart-backend.yaml:

```YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudmart-backend-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudmart-backend-app
  template:
    metadata:
      labels:
        app: cloudmart-backend-app
    spec:
      serviceAccountName: cloudmart-pod-execution-role
      containers:
      - name: cloudmart-backend-app
        image: public.ecr.aws/l4c0j8h9/cloudmaster-backend:latest
        env:
        - name: PORT
          value: "5000"
        - name: AWS_REGION
          value: "us-east-1"
        - name: BEDROCK_AGENT_ID
          value: "xxxx"
        - name: BEDROCK_AGENT_ALIAS_ID
          value: "xxxx"
        - name: OPENAI_API_KEY
          value: "xxxx"
        - name: OPENAI_ASSISTANT_ID
          value: "xxxx"
---

apiVersion: v1
kind: Service
metadata:
  name: cloudmart-backend-app-service
spec:
  type: LoadBalancer
  selector:
    app: cloudmart-backend-app
  ports:
    - protocol: TCP
      port: 5000
      targetPort: 5000
```

&nbsp;

**Atualize o deployment no Kubernetes**  
`kubectl apply -f cloudmart-backend.yaml`

&nbsp;

**Teste o AI Assistant**\*\*:\*\*

**![09baad914c94a988b8203cdc025463b8.png](_resources/09baad914c94a988b8203cdc025463b8.png)**

&nbsp;

&nbsp;

# Dia 05 - Indo para MultiCloud: DW/BI no Google Cloud & AnÃ¡lise de Sentimentos com Microsoft Azure AI

&nbsp;

> ğŸ’¡ Profissionais de TI nÃ£o serÃ£o substituÃ­dos pela IA, mas sim por alguÃ©m que **SABE usar** IA.

&nbsp;

**A evoluÃ§Ã£o das posiÃ§Ãµes**

Engenheiro de infraestrutura on-premisses -> **Engenheiro de Cloud Infra**

![25f0dc6cbc239982e5e5e969624d2993.png](_resources/25f0dc6cbc239982e5e5e969624d2993.png)

Engengeiro de Suporte -> **Engenheiro de Suporte Cloud**

![1f3d46a7a36351eb12791e9a97416467.png](_resources/1f3d46a7a36351eb12791e9a97416467.png)  
<br/>

Engenheiro de SeguranÃ§a -> **Engenheiro de SeguranÃ§a Cloud**

![561c1eec336f69d661d55917dff58901.png](_resources/561c1eec336f69d661d55917dff58901.png)

Administrador de Sistemas -> **Administrador de Sistemas Cloud**

![ef5f0a8c2230f49a8c8a2d5f9ab5badb.png](_resources/ef5f0a8c2230f49a8c8a2d5f9ab5badb.png)

Gerente de TI -> **Gerente de TI especializado em Cloud e DevOps**

![9acd403ac889b2577932db1d1c0f0fc1.png](_resources/9acd403ac889b2577932db1d1c0f0fc1.png)

Desenvolvedor -> **Desenvolvedor Cloud**

![07090bffc2ea50a3776345cc8b5dbbda.png](_resources/07090bffc2ea50a3776345cc8b5dbbda.png)

Engenheiro Clooud Infra, DBA especializado em Cloud, Desenvolvedor Cloud >  
**Arquiteto Cloud, Engenheiro Cloud, Site Reliability Engineering (SRE)**

![4a5bbac28fbb99ea7d4aa0918e14af2c.png](_resources/4a5bbac28fbb99ea7d4aa0918e14af2c.png)

**AULA PRÃTICA**

**Configure a funÃ§Ã£o lambda:**

**Instale as dependÃªncias requiridas:**  
`cd src/lambda/addToBigQuery`  
`sudo yum install npm`  
`npm install`  
**Edite** o arquivo `google_credentials.json` e cole o conteÃºdo com a sua chave.  
**Crie** o arquivo zip do diretÃ³rio completo:  
`zip -r dynamodb_to_bigquery.zip .`  
Retorne ao diretÃ³rio raiz do projeto:  
`cd ..`

&nbsp;

**ConfiguraÃ§Ã£o do Terraform**  
Apague o arquivo main.tf e crie um novo:  
`rm main.tf`  
`nano main.tf`  
â€‹  
Adicione essas linhas no arquivo, substituindo o `GOOGLE_CLOUD_PROJECT_ID` pelo **nome do projeto** da **GCP**.

```Terraform
provider "aws" {  
Â Â region = "us-east-1" # Altere para sua regiÃ£o preferida  
}

# Tabelas DynamoDB  
resource "aws_dynamodb_table" "cloudmart_products" {  
Â Â name = "cloudmart-products"  
Â Â billing_mode = "PAY_PER_REQUEST"  
Â Â hash_key = "id"

&nbsp;Â attribute {  
Â Â Â Â name = "id"  
Â Â Â Â type = "S"  
Â Â }  
}

resource "aws_dynamodb_table" "cloudmart_orders" {  
Â Â name = "cloudmart-orders"  
Â Â billing_mode = "PAY_PER_REQUEST"  
Â Â hash_key = "id"

&nbsp;Â attribute {  
Â Â Â Â name = "id"  
Â Â Â Â type = "S"  
Â Â }

&nbsp;Â stream_enabled = true  
Â Â stream_view_type = "NEW_AND_OLD_IMAGES"  
}

resource "aws_dynamodb_table" "cloudmart_tickets" {  
Â Â name = "cloudmart-tickets"  
Â Â billing_mode = "PAY_PER_REQUEST"  
Â Â hash_key = "id"

&nbsp;Â attribute {  
Â Â Â Â name = "id"  
Â Â Â Â type = "S"  
Â Â }  
}

# IAM Role for Lambda function  
resource "aws_iam_role" "lambda_role" {  
Â Â name = "cloudmart_lambda_role"

&nbsp;Â assume_role_policy = jsonencode({  
Â Â Â Â Version = "2012-10-17"  
Â Â Â Â Statement = [  
Â Â Â Â Â Â {  
Â Â Â Â Â Â Â Â Action = "sts:AssumeRole"  
Â Â Â Â Â Â Â Â Effect = "Allow"  
Â Â Â Â Â Â Â Â Principal = {  
Â Â Â Â Â Â Â Â Â Â Service = "lambda.amazonaws.com"  
Â Â Â Â Â Â Â Â }  
Â Â Â Â Â Â }  
Â Â Â Â ]  
Â Â })  
}

# IAM Policy for Lambda function  
resource "aws_iam_role_policy" "lambda_policy" {  
Â Â name = "cloudmart_lambda_policy"  
Â Â role = aws_iam_role.lambda_role.id

&nbsp;Â policy = jsonencode({  
Â Â Â Â Version = "2012-10-17"  
Â Â Â Â Statement = [  
Â Â Â Â Â Â {  
Â Â Â Â Â Â Â Â Effect = "Allow"  
Â Â Â Â Â Â Â Â Action = [  
Â Â Â Â Â Â Â Â Â Â "dynamodb:Scan",  
Â Â Â Â Â Â Â Â Â Â "dynamodb:GetRecords",  
Â Â Â Â Â Â Â Â Â Â "dynamodb:GetShardIterator",  
Â Â Â Â Â Â Â Â Â Â "dynamodb:DescribeStream",  
Â Â Â Â Â Â Â Â Â Â "dynamodb:ListStreams",  
Â Â Â Â Â Â Â Â Â Â "logs:CreateLogGroup",  
Â Â Â Â Â Â Â Â Â Â "logs:CreateLogStream",  
Â Â Â Â Â Â Â Â Â Â "logs:PutLogEvents"  
Â Â Â Â Â Â Â Â ]  
Â Â Â Â Â Â Â Â Resource = [  
Â Â Â Â Â Â Â Â Â Â aws_dynamodb_table.cloudmart_products.arn,  
Â Â Â Â Â Â Â Â Â Â aws_dynamodb_table.cloudmart_orders.arn,  
Â Â Â Â Â Â Â Â Â Â "${aws_dynamodb_table.cloudmart_orders.arn}/stream/*",  
Â Â Â Â Â Â Â Â Â Â aws_dynamodb_table.cloudmart_tickets.arn,  
Â Â Â Â Â Â Â Â Â Â "arn:aws:logs:*:*:*"  
Â Â Â Â Â Â Â Â ]  
Â Â Â Â Â Â }  
Â Â Â Â ]  
Â Â })  
}

# Lambda function for listing products  
resource "aws_lambda_function" "list_products" {  
Â Â filename = "list_products.zip"  
Â Â function_name = "cloudmart-list-products"  
Â Â role = aws_iam_role.lambda_role.arn  
Â Â handler = "index.handler"  
Â Â runtime = "nodejs20.x"  
Â Â source_code_hash = filebase64sha256("list_products.zip")

&nbsp;Â environment {  
Â Â Â Â variables = {  
Â Â Â Â Â Â PRODUCTS_TABLE = aws_dynamodb_table.cloudmart_products.name  
Â Â Â Â }  
Â Â }  
}

# Lambda permission for Bedrock  
resource "aws_lambda_permission" "allow_bedrock" {  
Â Â statement_id = "AllowBedrockInvoke"  
Â Â action = "lambda:InvokeFunction"  
Â Â function_name = aws_lambda_function.list_products.function_name  
Â Â principal = "bedrock.amazonaws.com"  
}

# Output the ARN of the Lambda function  
output "list_products_function_arn" {  
Â Â value = aws_lambda_function.list_products.arn  
}

# Lambda function for DynamoDB to BigQuery  
resource "aws_lambda_function" "dynamodb_to_bigquery" {  
Â Â filename = "../challenge-day2/backend/src/lambda/addToBigQuery/dynamodb_to_bigquery.zip"  
Â Â function_name = "cloudmart-dynamodb-to-bigquery"  
Â Â role = aws_iam_role.lambda_role.arn  
Â Â handler = "index.handler"  
Â Â runtime = "nodejs20.x"  
Â Â source_code_hash = filebase64sha256("../challenge-day2/backend/src/lambda/addToBigQuery/dynamodb_to_bigquery.zip")

&nbsp;Â environment {  
Â Â Â Â variables = {  
Â Â Â Â Â Â GOOGLE_CLOUD_PROJECT_ID = "lustrous-bounty-436219-f1"  
Â Â Â Â Â Â BIGQUERY_DATASET_ID = "cloudmart"  
Â Â Â Â Â Â BIGQUERY_TABLE_ID = "cloudmart-orders"  
Â Â Â Â Â Â GOOGLE_APPLICATION_CREDENTIALS = "/var/task/google_credentials.json"  
Â Â Â Â }  
Â Â }  
}

# Lambda event source mapping for DynamoDB stream  
resource "aws_lambda_event_source_mapping" "dynamodb_stream" {  
Â Â event_source_arn = aws_dynamodb_table.cloudmart_orders.stream_arn  
Â Â function_name = aws_lambda_function.dynamodb_to_bigquery.arn  
Â Â starting_position = "LATEST"  
}
```

â€‹  
Agora, execute `terraform apply` .

&nbsp;

**Verificar se o stream foi ativado, no DynamoDB:**

DynamoDB > Tabelas > cloudmart-orders![a1963807cc9bab64ead79f0366313d1c.png](_resources/a1963807cc9bab64ead79f0366313d1c.png)

**Azure Text Analytics Setup**

Siga estas etapas para configurar o Azure Text Analytics para anÃ¡lise de sentimento:

**1 - Crie uma conta do Azure:**

- Acesse o portal do Azure (https://portal.azure.com/).
- FaÃ§a login ou crie uma nova conta se ainda nÃ£o tiver uma.

**2 - Crie um recurso:**

- No portal do Azure, clique em â€œCriar um recursoâ€.
- Procure por "Text Analytics" e selecione-o.
- Clique em "Criar".

**3 - Configure o recurso:**

- Escolha sua assinatura e grupo de recursos (crie um novo, se necessÃ¡rio).
- Nomeie o recurso (por exemplo, "cloudmart-text-analytics").
- Escolha sua regiÃ£o e nÃ­vel de preÃ§os.
- Clique em â€œRevisar + criarâ€ e depois em â€œCriarâ€.

**4 - Obtenha o endpoint e a chave:**

- Depois que o recurso for criado, vÃ¡ para sua pÃ¡gina de visÃ£o geral.
- No menu esquerdo, em â€œGerenciamento de Recursosâ€, clique em â€œChaves e Endpointâ€.
- Copie o URL do endpoint e uma das chaves.

&nbsp;

**Deploy das mudanÃ§as para o Backend**

Abra o arquivo cloudmart-backend.yaml:`nano cloudmart-backend.yaml`

&nbsp;

```YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudmart-backend-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudmart-backend-app
  template:
    metadata:
      labels:
        app: cloudmart-backend-app
    spec:
      serviceAccountName: cloudmart-pod-execution-role
      containers:
      - name: cloudmart-backend-app
        image: public.ecr.aws/l4c0j8h9/cloudmaster-backend:latest
        env:
        - name: PORT
          value: "5000"
        - name: AWS_REGION
          value: "us-east-1"
        - name: BEDROCK_AGENT_ID
          value: "xxxx"
        - name: BEDROCK_AGENT_ALIAS_ID
          value: "xxxx"
        - name: OPENAI_API_KEY
          value: "xxxx"
        - name: OPENAI_ASSISTANT_ID
          value: "xxxx"
        - name: AZURE_ENDPOINT
          value: "xxxx"
        - name: AZURE_API_KEY
          value: "xxxx"
        
---

apiVersion: v1
kind: Service
metadata:
  name: cloudmart-backend-app-service
spec:
  type: LoadBalancer
  selector:
    app: cloudmart-backend-app
  ports:
    - protocol: TCP
      port: 5000
      targetPort: 5000
```

&nbsp;

**FaÃ§a o build de uma nova imagem no ECR**

`Seguir os passos de push no ECR`

ğŸ“ O Docker tem uma inteligÃªncia de camadas que identifica em quais camadas (layers) que houveram alteraÃ§Ãµes de cÃ³digo, para agilizar o processo de push.

![99f572afe509742849bc2e075b5bba94.png](_resources/99f572afe509742849bc2e075b5bba94.png)

&nbsp;

**Atualize o deployment no Kubernetes**

`kubectl apply -f cloudmart-backend.yaml`

==*O Kubernetes Ã© considerado **zero downtime** pois durante o processo de atualizaÃ§Ã£o do cÃ³digo, ele cria um **novo pod**Â com as mudanÃ§as mais recentes e comeÃ§a a direcionar as requisiÃ§Ãµes para esse novo pod. Somente quando todas as requisiÃ§Ãµes estÃ£o sendo atendidas pelo novo pod, o podÂ antigo Ã© encerrado.*==

&nbsp;

# CONCLUSÃƒO

Nos Ãºltimos cinco dias, mergulhei de cabeÃ§a no mundo DevOps e MultiCloud, aprendendo e praticando tecnologias essenciais para automaÃ§Ã£o, orquestraÃ§Ã£o e integraÃ§Ã£o de aplicaÃ§Ãµes na nuvem.

No **Dia 1**, comecei automatizando o provisionamento de infraestrutura na AWS com **Terraform**, criando recursos como **EC2, S3 e IAM** de forma declarativa. AlÃ©m disso, utilizei o **Claude AI** para auxiliar na otimizaÃ§Ã£o dos meus cÃ³digos.

No **Dia 2**, avancei para a containerizaÃ§Ã£o e orquestraÃ§Ã£o, trabalhando com **Docker e Kubernetes** na AWS. Aprendi a criar imagens Docker para backend e frontend, configurando um **DynamoDB** como banco de dados. TambÃ©m entendi como Kubernetes gerencia contÃªineres de forma eficiente, escalÃ¡vel e confiÃ¡vel.

No **Dia 3**, aprofundei meu conhecimento sobre **CI/CD**, implementando pipelines DevOps na AWS. Usei o **Elastic Container Registry (ECR)** para armazenar imagens Docker e implementei o **Elastic Kubernetes Service (EKS)** para orquestraÃ§Ã£o automÃ¡tica. Foi um dia essencial para consolidar a ideia de automaÃ§Ã£o total no ciclo de vida da aplicaÃ§Ã£o.

No **Dia 4**, explorei a criaÃ§Ã£o de **agentes de IA** com **Amazon Bedrock e OpenAI**. Desenvolvi um assistente de recomendaÃ§Ãµes para e-commerce e um chatbot de suporte ao cliente, ambos integrados com APIs externas e modelos de IA generativa.

No **Dia 5**, expandi a aplicaÃ§Ã£o para um ambiente **MultiCloud**, usando **Google Cloud** para processamento de dados com **BigQuery** e **Microsoft Azure AI** para anÃ¡lise de sentimentos. Implementei um fluxo de dados do **DynamoDB da AWS para o BigQuery da GCP**, automatizando a ingestÃ£o e anÃ¡lise de informaÃ§Ãµes.

Foi uma experiÃªncia intensa e transformadora, onde pude consolidar conceitos fundamentais de DevOps, Cloud e IA, aplicando-os em um projeto real e totalmente integrado entre mÃºltiplas plataformas. ğŸš€